{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\Car_Price_Predictions\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\Car_Price_Predictions'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    preprocessor_path: Path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CarPrice.constants import *\n",
    "from src.CarPrice.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            preprocessor_path = config.preprocessor_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.CarPrice.logger import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,OrdinalEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data_transformer_obj(self):\n",
    "        '''\n",
    "        This function is responsible for data transformation\n",
    "        '''\n",
    "        try:\n",
    "            # Define which columns should be ordinal-encoded and which should be scaled\n",
    "            numerical_columns=['Present_Price', \n",
    "                                 'Kms_Driven', 'Owner', \n",
    "                                 'car_age']\n",
    "            categorical_columns=[\n",
    "                'Fuel_Type', 'Seller_Type', 'Transmission'\n",
    "            ]\n",
    "            \n",
    "            # Define the custom ranking for each ordinal variable\n",
    "            Fuel_Type = ['Petrol' ,'Diesel', 'CNG']\n",
    "            Seller_Type = ['Dealer' ,'Individual']\n",
    "            Transmission = ['Manual', 'Automatic']\n",
    "            \n",
    "\n",
    "            # Numerical Pipeline\n",
    "            num_pipeline = Pipeline(\n",
    "                steps = [\n",
    "                ('imputer',SimpleImputer(strategy='median')),\n",
    "                ('scaler',StandardScaler())                \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Categorical Pipeline\n",
    "            cat_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinal_encoder',OrdinalEncoder(categories=[Fuel_Type,\n",
    "                Seller_Type,\n",
    "                Transmission,\n",
    "                ])),\n",
    "                ('scaler',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(f'Categorical Columns : {categorical_columns}')\n",
    "            logging.info(f'Numerical Columns   : {numerical_columns}')\n",
    "\n",
    "            preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                ('num_pipeline',num_pipeline,numerical_columns),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_columns)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in get_data_transformer_object: {str(e)}\")\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            train_data_path = 'artifacts/data_ingestion/unzipped_data/train_data.csv'\n",
    "            test_data_path = 'artifacts/data_ingestion/unzipped_data/test_data.csv'\n",
    "\n",
    "            logging.info(\"Read train and test data completed\")\n",
    "\n",
    "            logging.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            # Read training and test data\n",
    "            train_df = pd.read_csv(train_data_path)\n",
    "            test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "            logging.info('Read train and test data completed')\n",
    "            logging.info(f'Train Dataframe Head : \\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test Dataframe Head  : \\n{test_df.head().to_string()}')\n",
    "\n",
    "            train_df['Current Year']=2023\n",
    "            test_df['Current Year']=2023\n",
    "\n",
    "            train_df['no_year']=train_df['Current Year']- train_df['Year']\n",
    "            test_df['no_year']=test_df['Current Year']- test_df['Year']\n",
    "\n",
    "            train_df.drop(['Year', 'Current Year'],axis=1,inplace=True)\n",
    "            test_df.drop(['Year', 'Current Year'],axis=1,inplace=True)\n",
    "\n",
    "            logging.info('Obtaining preprocessing object')\n",
    "\n",
    "            preprocessing_obj = self.get_data_transformer_obj()\n",
    "\n",
    "            target_column_name = 'Selling_Price'\n",
    "\n",
    "            # Separate input features and target features\n",
    "            input_feature_train_df = train_df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df = test_df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "\n",
    "            # Apply the preprocessing object on training and test input features\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            # Combine input features and target features\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            \n",
    "            test_arr = np.c_[\n",
    "                input_feature_test_arr, np.array(target_feature_test_df)\n",
    "            ]\n",
    "\n",
    "            # Save preprocessing object\n",
    "            preprocessing_obj_file = os.path.join(\"artifacts\", 'data_transformation', 'preprocessing_obj.pkl')\n",
    "            with open(preprocessing_obj_file, 'wb') as file:\n",
    "                pickle.dump(preprocessing_obj, file)\n",
    "\n",
    "            logging.info(\"Saved preprocessing object.\")\n",
    "            logging.info(\"Transformation of the data is completed\")\n",
    "            \n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr,\n",
    "                preprocessing_obj_file\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in initiate_data_transformation: {str(e)}\")\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 20:53:43,675: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-09-12 20:53:43,678: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-09-12 20:53:43,679: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 20:53:43,734: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2023-09-12 20:53:43,736: INFO: 3596685838: Read train and test data completed]\n",
      "[2023-09-12 20:53:43,737: INFO: 3596685838: Obtaining preprocessing object]\n",
      "[2023-09-12 20:53:43,766: INFO: 3596685838: Read train and test data completed]\n",
      "[2023-09-12 20:53:43,773: INFO: 3596685838: Train Dataframe Head : \n",
      "   Selling_Price  Present_Price  Kms_Driven Fuel_Type Seller_Type Transmission  Owner  car_age\n",
      "0           0.25          0.750       26000    Petrol  Individual       Manual      1       15\n",
      "1           0.75          0.950        3500    Petrol  Individual       Manual      0        6\n",
      "2           0.20          0.787       50000    Petrol  Individual       Manual      0       15\n",
      "3           3.95          6.800       36000    Petrol      Dealer       Manual      0        8\n",
      "4           1.15          1.500        8700    Petrol  Individual       Manual      0        7]\n",
      "[2023-09-12 20:53:43,778: INFO: 3596685838: Test Dataframe Head  : \n",
      "   Selling_Price  Present_Price  Kms_Driven Fuel_Type Seller_Type Transmission  Owner  car_age\n",
      "0           0.35           0.57       24000    Petrol  Individual    Automatic      0        7\n",
      "1          10.11          13.60       10980    Petrol      Dealer       Manual      0        7\n",
      "2           4.95           9.40       60000    Diesel      Dealer       Manual      0       11\n",
      "3           0.15           0.57       35000    Petrol  Individual       Manual      1       12\n",
      "4           6.95          18.61       40001    Petrol      Dealer       Manual      0       10]\n",
      "[2023-09-12 20:53:43,779: INFO: 3596685838: Obtaining preprocessing object]\n",
      "[2023-09-12 20:53:43,780: INFO: 3596685838: Categorical Columns : ['Fuel_Type', 'Seller_Type', 'Transmission']]\n",
      "[2023-09-12 20:53:43,781: INFO: 3596685838: Numerical Columns   : ['Present_Price', 'Kms_Driven', 'Owner', 'car_age']]\n",
      "[2023-09-12 20:53:43,816: INFO: 3596685838: Saved preprocessing object.]\n",
      "[2023-09-12 20:53:43,817: INFO: 3596685838: Transformation of the data is completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
